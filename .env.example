# =============================================================================
# RAG Documentation Service Configuration
# =============================================================================
# Copy this file to .env and customize for your environment

# -----------------------------------------------------------------------------
# Embedding Model Configuration
# -----------------------------------------------------------------------------
# Choose based on your available VRAM:
#   CPU/4GB:    sentence-transformers/all-MiniLM-L6-v2 (default)
#   8-16GB:     BAAI/bge-large-en-v1.5
#   24-50GB:    intfloat/e5-mistral-7b-instruct
#   50-100GB:   Salesforce/SFR-Embedding-Mistral
#   100-200GB:  nvidia/NV-Embed-v2

EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Device selection: auto, cpu, cuda, mps
# "auto" will detect the best available device
DEVICE=auto

# Batch size for embedding generation (reduce if OOM)
EMBEDDING_BATCH_SIZE=32

# -----------------------------------------------------------------------------
# Vector Store Configuration
# -----------------------------------------------------------------------------
# Backend: faiss or chroma
VECTOR_STORE_BACKEND=faiss

# Persistence directories
FAISS_INDEX_DIR=./data/index
CHROMA_PERSIST_DIR=./data/chroma

# Default collection name
DEFAULT_COLLECTION=documents

# -----------------------------------------------------------------------------
# Document Processing
# -----------------------------------------------------------------------------
# Chunk size in characters
CHUNK_SIZE=512

# Overlap between chunks
CHUNK_OVERLAP=50

# PDF processing strategy: fast, hi_res, ocr_only
PDF_STRATEGY=fast

# -----------------------------------------------------------------------------
# GraphRAG Configuration
# -----------------------------------------------------------------------------
# Enable hybrid vector + graph retrieval
ENABLE_GRAPH_RAG=false

# Graph store backend: memory (NetworkX) or neo4j
GRAPH_STORE_BACKEND=memory

# Neo4j connection (only needed if GRAPH_STORE_BACKEND=neo4j)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password

# Query routing: pattern (rule-based) or llm (uses Ollama)
ROUTER_MODE=pattern

# Entity extraction: rule_based or llm (uses Ollama)
ENTITY_EXTRACTION_MODE=rule_based

# Extraction domain: general or mavlink (specialized for MAVLink protocols)
ENTITY_EXTRACTION_DOMAIN=general

# Ollama model for LLM-based routing/extraction (if enabled)
OLLAMA_MODEL=llama3.2

# -----------------------------------------------------------------------------
# Web UI Configuration
# -----------------------------------------------------------------------------
# Port for Gradio UI (auto-detects available port if in use)
UI_PORT=7860

# Create public shareable link
UI_SHARE=false

# -----------------------------------------------------------------------------
# API Configuration
# -----------------------------------------------------------------------------
HOST=0.0.0.0
PORT=8000

# CORS origins (comma-separated)
CORS_ORIGINS=http://localhost:3000,http://localhost:8080,http://localhost:7860

# API prefix
API_PREFIX=/api/v1

# -----------------------------------------------------------------------------
# Logging
# -----------------------------------------------------------------------------
LOG_LEVEL=INFO
